---
title: "Assignment 4"
date: "January 10, 2023"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE) # actually set the global chunk options. 
library("httr")
library("tidyverse")
library("DBI")
library("RSQLite")
library("RSelenium")
library("xml2")
library("rvest")
library("sf")
library("rnaturalearth")
library("tmap")
```

```{r}
#=========================================================
# Get Functions
#=========================================================
get_data <- function(url){
  data<- GET(url)
  
  data_parsed <- content(data, "parsed")
  
  return(data_parsed)
}

get_written_data <- function(base_url, skip_records, take_records){
  url <- paste0(base_url, skip_records, take_records) #construct first request
  
  written_data <- get_data(url) #get first request
  
  written_list <- list() #create a new list
  
  written_list <- append(written_list, written_data$results) #append first request to the list
  
  num_requests <- ceiling(written_data$totalResults / 100) #calculate number of requests needed
  
  for (i in 1:num_requests){ #for each request in num_requests
    
    cat("Getting request ", i, " out of ", num_requests, "\n") #update user
    
    skip_records <- skip_records + 100 #update the skip number
    
    url <- paste0(base_url, skip_records, take_records) #update the url
    
    written_data <- get_data(url) #get current request
    
    written_list <- append(written_list, written_data$results) #append current request to the list
    
    #add a pause
    Sys.sleep(2)
  }
  
  results <- map_df(written_list, create_written_df_row) #construct df with needed data
  
  return(results)
}

get_oral_data <- function(base_url, skip_records, take_records){
  url <- paste0(base_url, skip_records, take_records) #construct first request
  
  oral_data <- get_data(url) #get first request
  
  oral_list <- list() #create a new list
  
  oral_list <- append(oral_list, oral_data$Response) #append first request to the list

  num_requests <- ceiling(oral_data$PagingInfo$GlobalTotal / 100) #calculate number of requests needed
  
  for (i in 1:num_requests){ #for each request in num_requests
    
    cat("Getting request ", i, " out of ", num_requests, "\n") #update user
    
    skip_records <- skip_records + 100 #update the skip number
    
    url <- paste0(base_url, skip_records, take_records) #update the url
    
    oral_data <- get_data(url) #get current request
    
    oral_list <- append(oral_list, oral_data$Response) #append current request to the list
    
    #add a pause
    Sys.sleep(2)
  }
  
  results <- map_df(oral_list, create_oral_df_row) #construct df with needed data
  
  return(results)
}

get_geo_ids <- function(url, selector_list){
  # Create driver
  rD <- rsDriver(browser=c("firefox"), verbose = F, 
                   port = netstat::free_port(random = TRUE), 
                   chromever = NULL) 
  
  driver <- rD$client
  
  #Create list to store geo data
  geography_ids <- list()
  
  # Loop through constituencies
  for (constituency in member_constituencies$asking_member_from){
    cat("Getting data for ", constituency, "\n")
    
    #navigate to homepage
    driver$navigate(url)
    
    #wait for page to load
    Sys.sleep(2)
    
    tryCatch(
          {
            #try to find the search bar
            search_box <- driver$findElement(using = "xpath",
                                             value = selector_list$search_box)
          },
          error = function(e){ #if the search bar isn't found
            cat("Trying ", constituency, " again\n")
            
            # Add a pause
            Sys.sleep(2)
            
            # Try to find the search bar again
            search_box <- driver$findElement(using = "xpath",
                                             value = selector_list$search_box)
            
          }
        )
    
    # Send the constituency name into the search bar
    search_box$sendKeysToElement(list(constituency))
    
    # Wait for options to pop up
    Sys.sleep(2)
    
    # Set flag to indicate whether the appropriate option was found
    element_found <- FALSE
  
    while (!element_found) { #while the element has not been found
      
      tryCatch(
        {
          # Search for parliamentary constituency we are collecting data for
          option <- driver$findElement("xpath", 
                                       paste0("//div[contains(@class, 'listItem')",
                                       " and contains(., 'Parliamentary constituency')]"))
          
          # If the element is found, set the flag to exit the loop
          element_found <- TRUE
        },
        error = function(e) { # If the element is not found
          cat("Trying ", constituency, " again\n")
          
          # Add a pause
          Sys.sleep(2)
          
          # Try to find the option again
          option <- driver$findElement("xpath", 
                                       paste0("//div[contains(@class, 'listItem')",
                                       " and contains(., 'Parliamentary constituency')]"))
        }
      )
    }
    
    # Click that parliamentary constituency
    option$clickElement()
    
    # Wait for the page to load
    Sys.sleep(2)
    
    #Get the string that has the geographic ID in it
    geo_id <- driver$findElement("xpath", 
                                 '//*[@id="main"]/div[2]/div/p')$getElementText()
    
    # Add the string to the list
    geography_ids <- c(geography_ids, geo_id)
  }
  
  driver$close()
  
  return(geography_ids)
}

get_region <- function(link_texts) {
  for (link_text in link_texts) {
    if ("England" %in% link_text) {
      return("England")
    } else if ("Scotland" %in% link_text) {
      return("Scotland")
    } else if ("Northern Ireland" %in% link_text) {
      return("Northern Ireland")
    } else if ("Wales" %in% link_text) {
      return("Wales")
    }
  }
  return(NA)  # If none of the regions are found
}

get_regions <- function(df){
  base_url <- 'https://www.ons.gov.uk/visualisations/areas/'

  regions <- c()
  
  for (constituency_id in df$geo_ids){
    cat("Getting data for ", constituency_id, "\n")
    
    url <- paste0(base_url, constituency_id, "/")
    
    html_content <- read_html(url)
    
    link_data <- get_all_links(html_content)
  
    link_data$link_texts
    
    region <- get_region(link_data)
    
    regions <- c(regions, region)
  }
  return(regions)
}

get_all_links <- function(html){ # Gets all links from the input HTML
  
  # Extract all hyperlink elements from the provided HTML
  link_elements <- html %>% 
    html_elements(css = "a")
  
  # Extract the text content from the extracted urls.
  link_texts <- link_elements %>% html_text()
  
  # Create a list containing the elements and their corresponding texts
  link_data <- list("link_elements" = link_elements, 
                    "link_texts" = link_texts)
  
  # Return the created list containing link_elements and link_texts.
  return(link_data)
}

#=========================================================
# Create Functions
#=========================================================
create_written_df_row <- function(element){
  new_row <- tibble(
    asking_member_id = element$value$askingMemberId,  
    asking_member_name = element$value$askingMember$name,
    asking_member_party = element$value$askingMember$party,
    asking_member_from = element$value$askingMember$memberFrom,
    answering_body_name = element$value$answeringBodyName
  )
  return(new_row)
}

create_oral_df_row <- function(element){
  new_row <- tibble(
    asking_member_id = element$AskingMemberId,  
    asking_member_name = element$AskingMember$Name,
    asking_member_party = element$AskingMember$Party,
    asking_member_from = element$AskingMember$Constituency,
    answering_body_name = element$AnsweringBody
  )
  return(new_row)
}

#=========================================================
# Processing Functions
#=========================================================
process_questions <- function(df){
  # Group the combined data by asking_member_id 
  df_grouped <- df %>%
    group_by(asking_member_id) %>%
  
    # Summarize the data: calculate counts and majority-related columns
    summarise(
      health_welfare_count = sum(answering_body_name %in% c("Department of Health and Social Care", 
                                                            "Department for Work and Pensions")),
      
      economic_count = sum(!answering_body_name %in% c("Department of Health and Social Care", 
                                                       "Department for Work and Pensions")),
      
      health_welfare_proportion = round(health_welfare_count/ (health_welfare_count + 
                                                                 economic_count), 
                                        2),
      
      economic_proportion = 1- health_welfare_proportion)

  # Left join the grouped data with additional information from the original df
  df_processed <- left_join(df_grouped, df %>%
                                         
                         # Keep only distinct records based on asking_member_id
                         distinct(asking_member_id, .keep_all = TRUE), 
                         
                         by = "asking_member_id") %>%
    
    # Select specific columns for the final processed dataframe
    select(c(asking_member_name, 
             asking_member_party, 
             asking_member_from, 
             health_welfare_proportion, 
             economic_proportion))
  
  return (df_processed)
}

#=========================================================
# Cleaning Functions
#=========================================================
clean_geo_id <- function(input_string) {
  # Extract text within parentheses
  geo_id_processed <- regmatches(input_string,
                                 regexpr("\\(([^)]+)\\)",
                                         input_string))
  
  # Remove parentheses
  geo_clean <- gsub("[()]", "", geo_id_processed)
  
  # Return the cleaned result
  return(geo_clean)
}
```

```{r}
# Set the path to the SQLite database
database = 'database/parliament_data.db'
```

```{r eval=FALSE}
# Set the base URL for the written questions API with specific parameters
written_base_url <- paste0('https://questions-statements-api.parliament.uk/',
                           'api/writtenquestions/questions?', 
                           'tabledWhenFrom=2022-01-01&tabledWhenTo=2022-12-31',
                           '&includeWithdrawn=true&expandMember=true',
                           '&answeringBodies=17&answeringBodies=14&answeringBodies=214',
                           '&answeringBodies=202&answeringBodies=29',
                           '&house=Commons&skip=')

# Set the number of records to skip for pagination
written_skip_records <- 0

# Set the number of records to take per request
written_take_records <- '&take=100'

# Retrieve data using the written questions API
written_df <- get_written_data(written_base_url,
                               written_skip_records,
                               written_take_records)

# Set the base URL for the oral questions API with specific parameters
oral_base_url <- paste0('https://oralquestionsandmotions-api.parliament.uk',
                        '/oralquestions/list?',
                        'parameters.answeringDateStart=2022-01-01',
                        '&parameters.answeringDateEnd=2022-12-31',
                        '&parameters.answeringBodyIds=17&parameters.answeringBodyIds=14',
                        '&parameters.answeringBodyIds=214&parameters.answeringBodyIds=202',
                        '&parameters.answeringBodyIds=29&parameters.skip=')

# Set the number of records to skip for pagination
oral_skip_records <- 0

# Set the number of records to take per request
oral_take_records <- '&parameters.take=100'

# Retrieve data using the oral questions API
oral_df <- get_oral_data(oral_base_url,
                         oral_skip_records,
                         oral_take_records)

# Combine written and oral question data 
all_questions_df <- rbind(written_df, oral_df)

all_questions_processed <- process_questions(all_questions_df)

# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

# Write the processed data into the database
dbWriteTable(db, "member_details", all_questions_processed)

# Disconnect from the database
dbDisconnect(db)

```

### Introduction

Oral and written questions enable Members of Parliament (MPs) in the House of Commons to scrutinize the government's actions and policies. In this investigation, I aim to answer the following questions:

- Does party affiliation influence the focus of MPs' questions in the House of Commons? We will focus specifically on written and oral questions related to health and welfare vs. economic questions tabled and answered in 2022.

- To what extent do variations in MPs' rates of posing questions about health and welfare versus economic matters reflect regional disparities in their constituencies' overall health and employment statuses? This inquiry aims to investigate whether party affiliation remains the primary determinant of MPs' questioning patterns or if Members of Parliament demonstrate responsiveness to the specific needs of their constituents. In essence, does the questioning behavior align more with party conventions, or does it genuinely mirror the pressing concerns of the communities they represent?

### Data

I collected data from the [UK Parliament API](https://developer.parliament.uk/) and the (Office for National Statistics)[https://www.ons.gov.uk/] to do this analysis. 

For the UK Parliament API, I collected data on 562 written and oral questions from Members of Parliament. To understand which questions were about health and welfare vs economic, I only included questions that were answered by specific Answering Bodies to classify whether a question was about health,  welfare or economic issues. Questions answered by the Department for Business and Trade, Department for International Trade, and the Treasury  were counted as economic questions while questions answered by the Department for Work and Pensions and the Department of Health and Social Care were classified as health and welfare questions. Each time a question was answered by the answering body, 1 additional question was added to the MP's total count and I found the proportion of economic questions vs health and welfare questions for each MP. 

From the Parliamentary API, each member had data on the parlaimentary constituency they represented. To get the region each constituency was a apart of, I collected data from the Office of National Statistics to better highlight the difference between constituencies in Wales vs. England on the map. I also collected data on the general health of each constituency as well as their economic activity. I would expect constituencies with lower levels of general health to be aligned with the party that is asking more questions about health and welfare. I would also expect constituencies with higher levels of economic activity to be associated with the party that asks more questions about economic issues. 

I excluded questions by members who represented Scottish and Irish constituencies because analysis on the general health and economic activity of these areas were not readily available. Further research could explore these regions to get a more holistic view of this topic in the UK.

## Analysis

As seen in Figure 1. Members apart of the Labour Party asked a higher proportion of questions about health and welfare in 2022. Members of the Labour party whose health and welfare questions were less than 30% of their questions were outliers, while members of the conservative party had a wider range while some members asking no questions about health and welfare in any of their questions while also having a lower average of questions about health and welfare and a wider range between their 25th percentile and 75th percentile.

We can see in Figure 2 that members of the conservative party had a higher proportion of questions about economic issues compared to all other parties.

However, it is interesting to note that all parties have similar levels of asking questions about health, welfare and economic issues with economic issues being asked at much lower percentages compared to health and welfare questions. 

```{r}
db <- dbConnect(RSQLite::SQLite(), database)

member_constituencies <- dbGetQuery(db,
           "SELECT asking_member_name, 
           asking_member_from, 
           asking_member_party, 
           health_welfare_proportion, 
           economic_proportion 
           FROM member_details")

member_constituencies <- member_constituencies %>%
  mutate(asking_member_party = ifelse(
    asking_member_party %in% c("Conservative", 
                               "Labour",
                               "Scottish National Party"),
    asking_member_party,
    "Other")) 

ggplot(member_constituencies, aes(x = asking_member_party, y = health_welfare_proportion)) +
  geom_boxplot() +
  labs(title = "Percentage of Questions asked about Health and Welfare",
       x = "Asking Member Party", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +
  theme_minimal()

ggplot(member_constituencies, aes(x = asking_member_party, y = economic_proportion)) +
  geom_boxplot() +
  labs(title = "Percentage of Questions asked about Economic Topics",
       x = "Asking Member Party", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +
  theme_minimal()
  
```



```{r, eval=FALSE}
# Remove questions from Members who were removed from office mid-year
values_to_remove <- c("Neil Parish", "Kate Green")

# Remove values
member_constituencies <- member_constituencies[
  !member_constituencies$asking_member_name %in% values_to_remove, ]

search_box_path <- list('//*[@id="search"]')
names(search_box_path) <- "search_box"

url <- "https://www.ons.gov.uk/visualisations/areas/"

geography_ids <- get_geo_ids(url, search_box_path)

# Apply the function to each element in the list
cleaned_geo_ids <- lapply(geography_ids, clean_geo_id)

member_constituencies$geo_ids <- unlist(cleaned_geo_ids)

member_constituencies$region <- get_regions(member_constituencies)

member_constituencies_filtered <- member_constituencies %>%
  subset(region %in% c("England", "Wales"))
  
# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

# Write the processed data into the database
dbWriteTable(db, "member_details", 
             member_constituencies_filtered, 
             overwrite = TRUE)

# Disconnect from the database
dbDisconnect(db)

```

```{r}
# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

member_constituencies <- dbGetQuery(db,
           "SELECT asking_member_name, 
           asking_member_from, 
           asking_member_party, 
           health_welfare_proportion, 
           economic_proportion,
           region
           FROM member_details")

member_constituencies <- member_constituencies %>%
  mutate(asking_member_from = ifelse(asking_member_from == "Weston-super-Mare",
                                     "Weston-Super-Mare",
                                     asking_member_from))

# Disconnect from the database
dbDisconnect(db)

general_health <- read_csv("data/RM044-2021-2-filtered-2023-12-29T15_14_29Z.csv")

general_health_processed <- general_health %>%
  group_by(`Westminster Parliamentary constituencies`) %>%
  summarise(
    good_health_proportion = sum(Observation[
      `General health (6 categories)` %in% 
        c("Very good health", 
          "Good health")]) /
      sum(Observation)
  ) %>%
  ungroup()

health_data <- left_join(member_constituencies,
                         general_health_processed,
                         by = c("asking_member_from" = "Westminster Parliamentary constituencies"))

```

```{r fig.width = 13, fig.height = 13}
england_wales <- st_as_sf(ne_countries(geounit = c("England", 
                                        "Wales"),
                            type = "map_units"))

constituencies_shp <- read_sf(paste0("data/",
                              "Westminster_Parliamentary_Constituencies_",
                              "Dec_2021_UK_BFE_2022_-7013535748659767197/",
                              "PCON_DEC_2021_UK_BFE.shp"))

constituencies_shp_merged <- constituencies_shp %>%
  left_join(disability_data, 
            by = join_by(PCON21NM == asking_member_from)) %>%
  
  #remove rows that are not a aprt of our analysis
  filter(!is.na(region))

parties <- tm_shape(constituencies_shp_merged) +
  tm_borders(lwd=0.3) +
  tm_fill(col = "asking_member_party", palette = c("lightblue", "lightcoral", "grey80")) + +
  tm_layout(title = "Constituency Map") +
  # Highlight Wales with a thicker border
  tm_shape(constituencies_shp_merged[constituencies_shp_merged$region == "Wales", ]) +
  tm_borders(lwd=1)

heallth_map <- tm_shape(constituencies_shp_merged) +
  tm_borders() +
  tm_fill(
    col = "good_health_proportion",
    palette = "Blues",  # Choose a color palette
    style = "cont",
    alpha = 1
  ) +
  tm_layout(title = "Constituency Map") +
  tm_shape(constituencies_shp_merged[constituencies_shp_merged$region == "Wales", ]) +
  tm_borders(lwd=1)

tmap_arrange(parties, heallth_map, ncol = 2)
```



```{r, eval=FALSE}
library("nomisr")

test <- nomis_get_data(
  id = "NM_2055_1",
  measures = 20301,
  time = "2022",
  geography = "E00083860"
)

View(geography_nomis)

geography_nomis <- nomis_codelist("NM_2055_1", "geography")

geography_nomis_w_type <- nomis_get_metadata(id= "NM_2055_1", concept = "geography", type = "TYPE460")

metadata <- nomis_get_metadata("NM_2055_1")

View(geography_nomis)

data_info_w_type <- nomis_data_info("NM_2055_1")

View(merged_data_parties)









# Nomis API endpoint
url <- "http://www.nomisweb.co.uk/api/v01/dataset/NM_2055_1.jsonstat.json"

# Example geography code for a Westminster Parliamentary constituency (replace with the actual code)
constituency_code <- "E14001048"

# Example measures code (replace with the actual code)
measures_code <- "20301"

# Query parameters
query_params <- list(
  geography = constituency_code,
  measures = measures_code
)

# Make the API request
response <- GET(url, query = query_params)

# Parse the JSON response
json_data <- content(response, "parsed")









#set base url
base_url <- 'http://www.nomisweb.co.uk/api/v01/dataset/NM_2055_1.jsonstat.json?geography='

# Url suffix very good health
url_suffix_very_good <- '&measures=20301&c2021_health_6=1'
  
# Url suffix good health
url_suffix_good <- '&measures=20301&c2021_health_6=2'

datasets <- GET("http://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.json?search=name-TS037*")

dataset_parsed<- content(datasets, "parsed")

geographies <- GET("http://www.nomisweb.co.uk/api/v01/dataset/NM_2055_1.jsonstat.json?")

geographies_parsed <- content(geographies, "parsed")

geographies_df <- tibble(id = as.character(),
                      name = as.character())

for (i in seq_along(geographies_parsed$dimension$geography$category$label)) {
  geo_name <- names(geographies_parsed$dimension$geography$category$label)[i]
  geo_label <- geographies_parsed$dimension$geography$category$label[[i]]
  
  new_row <- tibble(id = geo_name, name = geo_label)
  
  geographies_df <- bind_rows(geographies_df, new_row)
  
}

member_geography_df <- merge(member_constituencies, 
                             geographies_df, 
                             by.x = "asking_member_from", 
                             by.y = "id", 
                             all.x = TRUE)

# get list options
health_options <- GET("http://www.nomisweb.co.uk/api/v01/dataset/NM_2055_1/geography.def.sdmx.json?")

options_parsed <- content(health_options, "parsed")

#get actual data
general_health <- GET("http://www.nomisweb.co.uk/api/v01/dataset/NM_2055_1.jsonstat.json?geography=2092957703&measures=20301&c2021_health_6=1")

health_parsed <- content(general_health, "parsed")

as.numeric(health_parsed$value[[1]])

#gender
#where they are from
```


This document contains the necessary commands and layout to meet the formatting requirements for MY472. You should use the template.Rmd file as the basis for your own answers to the assigned exercises.

## Formatting requirements

* You must present all results in full sentences, as you would in a report or academic piece of writing
  
  * If the exercise requires generating a table or figure, you should include at least one sentence introducing and explaining it. E.g. "The table below reports the counts of Wikipedia articles mentioning the LSE, by type of article."

* Unless stated otherwise, all code used to answer the exercises should be included as a code appendix at the end of the script. This formatting can be achieved by following the guidance in this template file.

* All code should be annotated with comments, to help the marker understand what you have done

* Your output should be replicable. Any result/table/figure that cannot be traced back to your code will not be marked

## Example of in-line figures without code

For those interested, we achieve the formatting requirements in two-steps: 1) in the `setup` chunk, we set `knitr::opts_chunk$set(echo = FALSE)` so that code is not included (echoed) by default in code chunks; 2) we add a specific chunk at the end of the file to collect and print *all* the code in the Rmarkdown file. Do not delete the final code chunk from the template!

For example, below we use a code chunk to generate random data and include a scatter plot in-line. The code used to generate this chart is only reported at the end of the document. 

```{r plot_example}
set.seed(89) # set a seed for R's psuedo-randomiser, for replicability.
x <- rnorm(100) # randomly draw 100 obs from normal distribution, save as object
y <- rnorm(100) 
plot(x,y) # two-way scatterplot using R's default plotting
```

In specific instances, however, you may be directed to report your code in-line (or you may want to do this to illustrate a specific point). In these cases, we can override the default behaviour by adding the chunk option `echo = TRUE` to a specific R chunk. When `echo=TRUE`, your code is presented in-line with any output displayed afterwards. The same code will also be included in the appendix at the bottom of the document (which is fine).

```{r echo_example, echo=TRUE}
# {[language] [chunk_name], [chunk_options]}
# here we use echo=TRUE to override our global options and make the chunk appear exactly here. 

print("This code chunk is visible in this section.")
```

## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to run (``evaluate'') the code here (it was already run before).
```
