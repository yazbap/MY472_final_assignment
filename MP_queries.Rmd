---
title: "Assignment 4"
date: "January 10, 2024"
output: html_document
---

```{r setup, include=FALSE} 
# Set global chunk options
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE) 

# Add libraries
library("httr")
library("tidyverse")
library("DBI")
library("RSQLite")
library("RSelenium")
library("xml2")
library("rvest")
library("sf")
library("rnaturalearth")
library("tmap")
library("gridExtra")
library("ggplot2")

```

```{r}
#=========================================================
# Get Functions
#=========================================================
get_data <- function(url){
  
  # Use GET function to retrieve data from the specified URL
  data <- GET(url)
  
  # Parse the retrieved data
  data_parsed <- content(data, "parsed")
  
  # Return the parsed data
  return(data_parsed)
}

get_written_data <- function(base_url, skip_records, take_records){
  url <- paste0(base_url, skip_records, take_records) #construct first request
  
  written_data <- get_data(url) #get first request
  
  written_list <- list() #create a new list
  
  written_list <- append(written_list, written_data$results) #append first request to the list
  
  num_requests <- ceiling(written_data$totalResults / 100) #calculate number of requests needed
  
  for (i in 1:num_requests){ #for each request in num_requests
    
    cat("Getting request ", i, " out of ", num_requests, "\n") #update user
    
    skip_records <- skip_records + 100 #update the skip number
    
    url <- paste0(base_url, skip_records, take_records) #update the url
    
    written_data <- get_data(url) #get current request
    
    written_list <- append(written_list, written_data$results) #append current request to the list
    
    #add a pause
    Sys.sleep(2)
  }
  
  results <- map_df(written_list, create_written_df_row) #construct df with needed data
  
  return(results)
}

get_oral_data <- function(base_url, skip_records, take_records){
  url <- paste0(base_url, skip_records, take_records) #construct first request
  
  oral_data <- get_data(url) #get first request
  
  oral_list <- list() #create a new list
  
  oral_list <- append(oral_list, oral_data$Response) #append first request to the list

  num_requests <- ceiling(oral_data$PagingInfo$GlobalTotal / 100) #calculate number of requests needed
  
  for (i in 1:num_requests){ #for each request in num_requests
    
    cat("Getting request ", i, " out of ", num_requests, "\n") #update user
    
    skip_records <- skip_records + 100 #update the skip number
    
    url <- paste0(base_url, skip_records, take_records) #update the url
    
    oral_data <- get_data(url) #get current request
    
    oral_list <- append(oral_list, oral_data$Response) #append current request to the list
    
    #add a pause
    Sys.sleep(2)
  }
  
  results <- map_df(oral_list, create_oral_df_row) #construct df with needed data
  
  return(results)
}

get_geo_ids <- function(url, selector_list, df){
  # Create driver
  rD <- rsDriver(browser=c("firefox"), verbose = F, 
                   port = netstat::free_port(random = TRUE), 
                   chromever = NULL) 
  
  driver <- rD$client
  
  #Create list to store geo data
  geography_ids <- list()
  
  # Loop through constituencies
  for (curr_constituency in df$constituency){
    cat("Getting data for ", curr_constituency, "\n")
    
    #navigate to homepage
    driver$navigate(url)
    
    #wait for page to load
    Sys.sleep(2)
    
    tryCatch(
          {
            #try to find the search bar
            search_box <- driver$findElement(using = "xpath",
                                             value = selector_list$search_box)
          },
          error = function(e){ #if the search bar isn't found
            cat("Trying ", constituency, " again\n")
            
            # Add a pause
            Sys.sleep(2)
            
            # Try to find the search bar again
            search_box <- driver$findElement(using = "xpath",
                                             value = selector_list$search_box)
            
          }
        )
    
    # Send the constituency name into the search bar
    search_box$sendKeysToElement(list(curr_constituency))
    
    # Wait for options to pop up
    Sys.sleep(2)
    
    # Set flag to indicate whether the appropriate option was found
    element_found <- FALSE
  
    while (!element_found) { #while the element has not been found
      
      tryCatch(
        {
          # Search for parliamentary constituency we are collecting data for
          option <- driver$findElement("xpath", 
                                       paste0("//div[contains(@class, 'listItem')",
                                       " and contains(., 'Parliamentary constituency')]"))
          
          # If the element is found, set the flag to exit the loop
          element_found <- TRUE
        },
        error = function(e) { # If the element is not found
          cat("Trying ", curr_constituency, " again\n")
          
          # Add a pause
          Sys.sleep(2)
          
          # Try to find the option again
          option <- driver$findElement("xpath", 
                                       paste0("//div[contains(@class, 'listItem')",
                                       " and contains(., 'Parliamentary constituency')]"))
        }
      )
    }
    
    # Click that parliamentary constituency
    option$clickElement()
    
    # Wait for the page to load
    Sys.sleep(2)
    
    #Get the string that has the geographic ID in it
    geo_id <- driver$findElement("xpath", 
                                 '//*[@id="main"]/div[2]/div/p')$getElementText()
    
    # Add the string to the list
    geography_ids <- c(geography_ids, geo_id)
  }
  
  # Close the driver
  driver$close()
  
  # Return the geo ids
  return(geography_ids)
}

get_region <- function(link_texts) {
  
  # Iterate through each link_text in the provided vector
  for (link_text in link_texts) {
    
    # Check if "England" is present in the current link_text
    if ("England" %in% link_text) {
      return("England")  # Return "England" if found
    } 
    # Check if "Scotland" is present in the current link_text
    else if ("Scotland" %in% link_text) {
      return("Scotland")  # Return "Scotland" if found
    } 
    # Check if "Northern Ireland" is present in the current link_text
    else if ("Northern Ireland" %in% link_text) {
      return("Northern Ireland")  # Return "Northern Ireland" if found
    } 
    # Check if "Wales" is present in the current link_text
    else if ("Wales" %in% link_text) {
      return("Wales")  # Return "Wales" if found
    }
  }
  
  # If none of the regions are found, return NA
  return(NA)
}

get_regions <- function(df){
  
  # Define the base URL for constructing complete URLs
  base_url <- 'https://www.ons.gov.uk/visualisations/areas/'
  
  # Initialize an empty vector to store the regions
  regions <- c()
  
  # Iterate through each constituency_id in the geo_ids column of the df
  for (constituency_id in df$geo_ids){
    
    # Print a message indicating the data retrieval process
    cat("Getting data for ", constituency_id, "\n")
    
    # Construct the complete URL
    url <- paste0(base_url, constituency_id, "/")
    
    # Read the HTML content from the constructed URL
    html_content <- read_html(url)
    
    # Extract all link texts from the HTML content using the get_all_links function
    link_data <- get_all_links(html_content)
  
    # Extract the link_texts component from the link_data
    link_data$link_texts
    
    # Use the get_region function to identify the region based on link_texts
    region <- get_region(link_data$link_texts)
    
    # Append the identified region to the regions vector
    regions <- c(regions, region)
  }
  
  # Return the vector containing the identified regions for each constituency
  return(regions)
}

get_all_links <- function(html){ # Gets all links from the input HTML
  
  # Extract all hyperlink elements from the provided HTML
  link_elements <- html %>% 
    html_elements(css = "a")
  
  # Extract the text content from the extracted urls.
  link_texts <- link_elements %>% html_text()
  
  # Create a list containing the elements and their corresponding texts
  link_data <- list("link_elements" = link_elements, 
                    "link_texts" = link_texts)
  
  # Return the created list containing link_elements and link_texts.
  return(link_data)
}

#=========================================================
# Create Functions
#=========================================================
create_written_df_row <- function(element){
  
  # Create a new row using the tibble function with specified column values
  new_row <- tibble(
    asking_member_id = element$value$askingMemberId,  
    asking_member_name = element$value$askingMember$name,
    asking_member_party = element$value$askingMember$party,
    asking_member_from = element$value$askingMember$memberFrom,
    answering_body_name = element$value$answeringBodyName
  )
  
  # Return the newly created row as a tibble
  return(new_row)
}

create_oral_df_row <- function(element){
  
  # Create a new row using the tibble function with specified column values
  new_row <- tibble(
    asking_member_id = element$AskingMemberId,  
    asking_member_name = element$AskingMember$Name,
    asking_member_party = element$AskingMember$Party,
    asking_member_from = element$AskingMember$Constituency,
    answering_body_name = element$AnsweringBody
  )
  
  # Return the newly created row as a tibble
  return(new_row)
}

#=========================================================
# Processing Functions
#=========================================================
process_questions <- function(df){
  # Group the combined data by asking_member_id 
  df_grouped <- df %>%
    group_by(asking_member_id) %>%
  
    # Summarize the data: calculate counts and majority-related columns
    summarise(
      health_welfare_count = sum(answering_body_name %in% c("Department of Health and Social Care", 
                                                            "Department for Work and Pensions")),
      
      economic_count = sum(!answering_body_name %in% c("Department of Health and Social Care", 
                                                       "Department for Work and Pensions")),
      
      health_welfare_proportion = round(health_welfare_count/ (health_welfare_count + 
                                                                 economic_count), 
                                        2),
      
      economic_proportion = 1- health_welfare_proportion)

  # Left join the grouped data with additional information from the original df
  df_processed <- left_join(df_grouped, df %>%
                                         
                         # Keep only distinct records based on asking_member_id
                         distinct(asking_member_id, .keep_all = TRUE), 
                         
                         by = "asking_member_id") %>%
    
    # Select specific columns for the final processed dataframe
    select(c(asking_member_name, 
             asking_member_party, 
             asking_member_from, 
             health_welfare_count,
             economic_count,
             health_welfare_proportion,
             economic_proportion)) %>%
    
    rename(constituency = asking_member_from)
  
  return (df_processed)
}

#=========================================================
# Cleaning Functions
#=========================================================
clean_geo_id <- function(input_string) {
  # Extract text within parentheses
  geo_id_processed <- regmatches(input_string,
                                 regexpr("\\(([^)]+)\\)",
                                         input_string))
  
  # Remove parentheses
  geo_clean <- gsub("[()]", "", geo_id_processed)
  
  # Return the cleaned result
  return(geo_clean)
}
```

```{r}
# Set the path to the SQLite database
database = 'database/parliament_data.db'

```

```{r eval=FALSE}
#=========================================================
# Get Written Question Data
#=========================================================

# Set the base URL for the written questions API with specific parameters
written_base_url <- paste0('https://questions-statements-api.parliament.uk/',
                           'api/writtenquestions/questions?', 
                           'tabledWhenFrom=2021-01-01&tabledWhenTo=2022-12-31',
                           '&includeWithdrawn=true&expandMember=true',
                           '&answeringBodies=17&answeringBodies=14&answeringBodies=214',
                           '&answeringBodies=202&answeringBodies=29',
                           '&house=Commons&skip=')

# Set the number of records to skip for pagination
written_skip_records <- 0

# Set the number of records to take per request
written_take_records <- '&take=100'

# Retrieve data using the written questions API
written_df <- get_written_data(written_base_url,
                               written_skip_records,
                               written_take_records)

#=========================================================
# Get Oral Question Data
#=========================================================

# Set the base URL for the oral questions API with specific parameters
oral_base_url <- paste0('https://oralquestionsandmotions-api.parliament.uk',
                        '/oralquestions/list?',
                        'parameters.answeringDateStart=2021-01-01',
                        '&parameters.answeringDateEnd=2022-12-31',
                        '&parameters.answeringBodyIds=17&parameters.answeringBodyIds=14',
                        '&parameters.answeringBodyIds=214&parameters.answeringBodyIds=202',
                        '&parameters.answeringBodyIds=29&parameters.skip=')

# Set the number of records to skip for pagination
oral_skip_records <- 0

# Set the number of records to take per request
oral_take_records <- '&parameters.take=100'

# Retrieve data using the oral questions API
oral_df <- get_oral_data(oral_base_url,
                         oral_skip_records,
                         oral_take_records)

#=========================================================
# Process Question Data
#=========================================================

# Combine written and oral question data 
all_questions_df <- rbind(written_df, oral_df)

all_questions_processed <- process_questions(all_questions_df)

# Remove questions from Members who were removed from office mid-year
values_to_remove <- c("Neil Parish", "Kate Green", "Sir David Amess",
                      "Mr Owen Paterson", "Jack Dromey", "Neil Gray",
                      "Tracy Brabin", "Mike Hill", "Imran Ahmad Khan")

# Remove values of members who left mid-year
member_constituencies <- all_questions_processed[
  !all_questions_processed$asking_member_name %in% values_to_remove, ]

#=========================================================
# Get Geo Data
#=========================================================

# Define search box Xpath
search_box_path <- list('//*[@id="search"]')
names(search_box_path) <- "search_box"

# Define homepage url
url <- "https://www.ons.gov.uk/visualisations/areas/"

# Geo geography ids for each constituency
geography_ids <- get_geo_ids(url, search_box_path, member_constituencies)

# Apply the function to each element in the list
cleaned_geo_ids <- lapply(geography_ids, clean_geo_id)

# Add geo ids to member constituencies
member_constituencies$geo_ids <- unlist(cleaned_geo_ids)

# Add regions to member constituencies
member_constituencies$region <- get_regions(member_constituencies)

# Filter only to constituencies in England and Wales
member_constituencies_filtered <- member_constituencies %>%
  subset(region %in% c("England", "Wales"))

# Clean up party column
parties_clean <- member_constituencies_filtered %>%
  mutate(asking_member_party = ifelse(
    asking_member_party %in% c("Conservative", 
                               "Labour"),
    asking_member_party,
    "Other")) %>%
  select (-geo_ids)

# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

# Write geo data into the database
dbWriteTable(db, "member_details", parties_clean)

# Disconnect from the database
dbDisconnect(db)

```

github repo: https://github.com/yazbap/MY472_final_assignment

### Introduction

In the realm of parliamentary scrutiny, where oral and written questions empower Members of Parliament (MPs) to delve into governmental actions and policies, this investigation seeks to unravel the dynamics shaping their interrogations. Two key questions guide this exploration:

- Is party affiliation a characteristic that discriminates between MP's that tend to ask questions about health and welfare vs economic issues?
  + This research focuses on written and oral inquiries pertaining to these topics tabled and answered from 2021-2022.

- To what degree do variations in MPs' rates of posing questions about health and welfare versus economic issues mirror regional disparities in their constituencies' broader health and economic landscapes? 
  + This inquiry explores whether MPs' questioning behavior is predominantly driven by party affiliation or genuinely reflects the urgent concerns of their constituents.

### Data

I collected data from the [UK Parliament API](https://developer.parliament.uk/), encompassing 36,452 written and oral questions posed by 563 Members of Parliament between January 2021 and December 2022. To discern the nature of these questions—whether they pertained to health and welfare or economic matters—I included questions answered by specific Answering Bodies. 

Economic questions were identified through responses from the Department for Business and Trade, Department for International Trade, and the Treasury. While the Department of Treasury is the primary entity for financial and economic policy, including the other two ensures a more comprehensive analysis of "economic issues," as they also support businesses in the UK.

Questions answered by the Department for Work and Pensions and the Department of Health and Social Care were categorized as health and welfare questions. I chose the former due to it being the biggest public service department in the UK delivering services like welfare. I chose the latter because they support ministers in leading the nation in health and social care policies.

I obtained general health levels, economic activity levels, and regional context from the Office for National Statistics for each constituency using R Selenium and .csv's downloaded from their website. These two data points, general health, and economic activity levels, are pivotal in assessing whether MPs' questioning behavior aligns with the urgent concerns of the communities they represent. To ensure the integrity of the analysis, I excluded 68 MPs representing Scottish and Irish constituencies due to limited data availability for these areas. Additionally, 9 members who left office mid-year were removed. Consequently, the analysis includes only the most recent members in office in England and Wales, totaling 486 members, and establishing a 1-to-1 relationship between each member and their constituency. If a constituency is missing from Figures 3, 4 and 5, it means there was no data for that constituency in the time frame of this analysis.

Table 1 shows the number of Labour and Conservative party members I collected data from as well as the number of questions each party asked. It should be noted while there are 77 more Conservative members than Labour party members in this analysis, Labour party members asked the majority of questions. The query from the database is also shown.

```{r, echo = TRUE}
# Connect to the SQLite database using the RSQLite package
db <- dbConnect(RSQLite::SQLite(), database)

# Retrieve all data from the "member_details" table in the SQLite database
data <- dbGetQuery(db,
           "SELECT * 
           FROM member_details")

# Disconnect from the SQLite database to free up resources
dbDisconnect(db)

# Perform data summarization:
show_data <- data %>%
  group_by(asking_member_party) %>%  # Group data by asking_member_party
  
  # Summarize the total number of health and welfare questions, economic questions, and count of members
  summarise(
    `Total Number of Health and Welfare Questions` = sum(health_welfare_count),
    `Total Number of Economic Questions` = sum(economic_count),
    Count = n()  
  ) %>%
  
  mutate(
    # Create a new column 'Total Questions' by summing health and welfare questions and economic questions
    `Total Questions` = `Total Number of Health and Welfare Questions` + `Total Number of Economic Questions`
  ) %>%
  
  # Rename the column asking_member_party to Party
  rename(Party = asking_member_party) %>%
  
  # Select relevant columns (Party, Count, Total Questions)
  select(Party, Count, `Total Questions`)

# Display the summarized data in a formatted table using knitr::kable
knitr::kable(show_data, caption = "Table 1: Number of members in each party")

```

## Analysis

Figures 1 and 2 help us answer research question #1. Figure 1 shows the Labour party's higher median percentage (around 81%) of questions related to health and welfare, while Figure 2 shows Conservatives lead in questions about economic issues with a median of 33%. The Labour party also exhibits a narrower range in questioning behavior, emphasizing a consistent focus on how they question the government. Conversely, Conservatives show a broader spectrum, despite their overall lower level of questioning the government.

With this knowledge, this helps us delve deeper into question #2 in which we discern whether this reality reflects disparities in the communities these MP's represent.

```{r fig.width = 13, fig.height = 7}
#=========================================================
# Box Plots
#=========================================================

# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

# Get boxplot data
boxplot_data <- dbGetQuery(db,
           "SELECT asking_member_party, 
           health_welfare_proportion, 
           economic_proportion 
           FROM member_details")

# Disconnect from the database
dbDisconnect(db)

# Create a boxplot for the percentage of questions asked about Health and Welfare
health_welfare_box <- ggplot(boxplot_data, 
                             aes(x = asking_member_party, 
                                 y = health_welfare_proportion)) +
  geom_boxplot() +  # Add a boxplot layer
  labs(title = "Figure 1 \n Percentage of Questions asked\nabout Health and Welfare",  # Set plot title
       x = "Asking Member Party", 
       y = "Percentage") +  # Set axis labels
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Format y-axis as percentage
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +  # Format y-axis labels
  theme_minimal()  # Use a minimal theme for the plot

# Create a boxplot for the percentage of questions asked about Economic Topics
economic_box <- ggplot(boxplot_data, 
                       aes(x = asking_member_party, 
                           y = economic_proportion)) +
  geom_boxplot() +  # Add a boxplot layer
  labs(title = "Figure 2 \n Percentage of Questions asked\nabout Economic Topics",  # Set plot title
       x = "Asking Member Party", 
       y = "Percentage") +  # Set axis labels
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Format y-axis as percentage
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +  # Format y-axis labels
  theme_minimal()  # Use a minimal theme for the plot

grid.arrange(health_welfare_box, economic_box, ncol=2)
```

```{r}
#=========================================================
# Create Maps
#=========================================================

# Connect to the SQLite database
db <- dbConnect(RSQLite::SQLite(), database)

# Get map data
map_data <- dbGetQuery(db,
           "SELECT constituency, 
           asking_member_party,
           region
           FROM member_details")

# Correct constituency to ensure correct table joinings
member_constituencies <- map_data %>%
  mutate(asking_member_from = ifelse(constituency == "Weston-super-Mare",
                                     "Weston-Super-Mare",
                                     constituency))

# Disconnect from the database
dbDisconnect(db)

general_health <- read_csv("data/RM044-2021-2-filtered-2023-12-29T15_14_29Z.csv")

economic_activity <- read_csv("data/TS066-2021-6-filtered-2024-01-05T11_06_34Z.csv")

# Calculate the proportion of respondents with good health in each constituency
general_health_processed <- general_health %>%
  group_by(`Westminster Parliamentary constituencies`) %>%
  summarise(
    good_health_proportion = sum(Observation[
      `General health (6 categories)` %in% 
        c("Very good health", 
          "Good health")]) /
      sum(Observation)
  ) %>%
  ungroup()

# Calculate the proportion of economically active respondents in each constituency
economic_processed <- economic_activity %>%
  group_by(`Westminster Parliamentary constituencies`) %>%
  summarise(
    economic_activity_proportion = sum(Observation[
      grepl("Economically active", `Economic activity status (20 categories)`)]) /
      sum(Observation)
  ) %>%
  ungroup()

# Merge processed health data with map_data based on the constituency column
health_data <- left_join(map_data,
                         general_health_processed,
                         by = c("constituency" = "Westminster Parliamentary constituencies"))

# Merge processed health and economic data with map_data based on the constituency column
health_economic_data <- left_join(health_data,
                                  economic_processed,
                                  by = c("constituency" = "Westminster Parliamentary constituencies"))


```


```{r}
# Get England and Wales shp data
england_wales <- st_as_sf(ne_countries(geounit = c("England", 
                                        "Wales"),
                            type = "map_units"))

# Get cosntituencies shp data
constituencies_shp <- read_sf(paste0("data/",
                              "Westminster_Parliamentary_Constituencies_",
                              "Dec_2021_UK_BFE_2022_-7013535748659767197/",
                              "PCON_DEC_2021_UK_BFE.shp"))

# Merge consitituency shp data with their health and economic statistics
constituencies_shp_merged <- constituencies_shp %>%
  left_join(health_economic_data, 
            by = join_by(PCON21NM == constituency)) %>%
  
  #remove rows that are not a aprt of our analysis
  filter(!is.na(region))

# Create map for parties
parties <- tm_shape(constituencies_shp_merged) +
  tm_borders(lwd=0.3) +
  tm_fill(col = "asking_member_party", 
          title = "Party",
          palette = c("lightblue", "lightcoral", "grey80")) +
  tm_layout(title = "Figure 3 \nConstituency Map by Party") +
  # Highlight Wales with a thicker border
  tm_shape(constituencies_shp_merged[constituencies_shp_merged$region == "Wales", ]) +
  tm_borders(lwd=1.2)

# Create map for health data
health_map <- tm_shape(constituencies_shp_merged) +
  tm_borders() +
  tm_fill(
    col = "good_health_proportion",
    title = "Percentage of constituents in Good Health",
    palette = "Greys",  # Choose a color palette
    style = "cont",
    alpha = 1
  ) +
  tm_layout(title = "Figure 4 \nConstituency Map by proportion of population in Good Health") +
  tm_shape(constituencies_shp_merged[constituencies_shp_merged$region == "Wales", ]) +
  tm_borders(lwd=1.2)

# Create map for economic data
economic_map <- tm_shape(constituencies_shp_merged) +
  tm_borders() +
  tm_fill(
    col = "economic_activity_proportion",
    title = "Percentage of Constituents who are Economically Active",
    palette = "Greens",  # Choose a color palette
    style = "cont",
    alpha = 1
  ) +
  tm_layout(title = "Figure 5 \nConstituency Map by Economic Activity Level") +
  tm_shape(constituencies_shp_merged[constituencies_shp_merged$region == "Wales", ]) +
  tm_borders(lwd=1.2)

```

Figure 3 illustrates party representation across England and Wales. Figures 4 and 5 depict the health and economic indicators mentioned in the Data section. Figures 4 and 5 show a concentration of higher economic activity and general health levels around the greater London area with these levels gradually decreasing as you move away from this area. While this hints at potential alignment with Labour party representation in that region, Figures 6 and 7 reveal similar average good health and economic activity levels for Conservative and Labour constituencies with the Labour party being slightly more economically diverse. This raises questions about the true reflection of constituency needs in MPs' behavior and the influence of external pressures.

In conclusion, while party affiliation discriminates questioning focus, regional health and economic indicators may not be strong factors that influence MP questioning behavior. This prompts further exploration into the multifaceted factors shaping MPs' behavior and how much constituent need shapes their focus.

```{r fig.width = 7, fig.height = 7}
parties #show parties map

```

```{r fig.width = 13, fig.height = 10}
#arrange economic and health maps side by side
tmap_arrange(health_map, economic_map, ncol = 2)

```


```{r}
#=========================================================
# Create Plots
#=========================================================

# Calculate mean and standard deviation of economically active constituents for each party
economically_active_mean_std <- health_economic_data %>%
  
  # For each group defined by 'asking_member_party'
  group_by(asking_member_party) %>%
  
  # Calculate the mean and standard deviation of the economic activity proportions
  summarise_at(vars(economic_activity_proportion), 
               list(`Average Percentage of Economically Active Constituents`= ~mean(., 
                                                                               na.rm = TRUE),
                    `Economically Active Standard Deviation`= ~sd(.,
                                                          na.rm = TRUE))) %>%
  as.data.frame()

# Plot economically_active_mean_std
economically_active_plot <- ggplot(economically_active_mean_std, 
       aes(x=asking_member_party, 
           y=`Average Percentage of Economically Active Constituents`)) +
  
  #Plot standard deviation
  geom_errorbar(aes(ymin=`Average Percentage of Economically Active Constituents`-
                      `Economically Active Standard Deviation`, 
                    ymax=`Average Percentage of Economically Active Constituents`+
                      `Economically Active Standard Deviation`), width=.3) +
  
  #Plot mean
  geom_point(size=2) +
  
  #Set axes
  labs(title = "Figure 7 \nMean and Standard Deviation\nfor Proportion of Economically Active Constituents",
       x = "Asking Member Party", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +
  
  theme_minimal()

# Calculate mean and standard deviation of the health of constituents for each party
good_health_mean_std <- health_economic_data %>%
  
  # For each group defined by 'asking_member_party'
  group_by(asking_member_party) %>%
  
  # Calculate the mean and standard deviation of the good health proportions
  summarise_at(vars(good_health_proportion), 
               list(`Average Percentage of Constituents in Good Health`= ~mean(., 
                                                                               na.rm = TRUE),
                    `Good Health Standard Deviation`= ~sd(.,
                                                          na.rm = TRUE))) %>%
  as.data.frame()

# Plot good_health_mean_std
good_health_plot <- ggplot(good_health_mean_std, 
       aes(x=asking_member_party, 
           y=`Average Percentage of Constituents in Good Health`)) +
  
  # Plot standard deviation
  geom_errorbar(aes(ymin=`Average Percentage of Constituents in Good Health`-
                      `Good Health Standard Deviation`, 
                    ymax=`Average Percentage of Constituents in Good Health`+
                      `Good Health Standard Deviation`), width=.3) +
  
  # Plot mean
  geom_point(size=2) +
  
  #Set axes
  labs(title = "Figure 6 \nMean and Standard Deviation\nfor Proportion of Constituents in Good Health",
       x = "Asking Member Party", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_y_continuous(labels = function(x) paste0(sprintf("%.0f", x*100), "%")) +
  
  theme_minimal()

```

```{r fig.width = 13, fig.height = 7}
grid.arrange(good_health_plot, economically_active_plot, ncol=2)

```


## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
```
